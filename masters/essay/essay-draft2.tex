\input{../preamble.tex}
\usepackage{indentfirst}
\begin{document}
\begin{center}
	\Large
	\begin{LARGE}
		Essay Draft 2 \\
	\end{LARGE}
	Isaac Martin \\
    Last compiled \today
\end{center}
\normalsize
\vspace{-2mm}
\hru

\tableofcontents
\newpage
\section*{Introduction}
Write this later.

\newpage
\section{Differential Operators}
One must first define fields before one defines vectors spaces, define rings before modules, and indeed, one must first understand the ring of differential operators before one can study $D$-modules. In this section we do exactly that. We first define the ring of differential operators relative to an arbitrary ring homomorphism and discuss some of its basic properties before zooming in on the case of the polynomial ring with field coefficients, whose ring of differential operators is called the Weyl algebra. This latter object will provide a more explicit setting and will motivate arguments in the general case. We conclude this section with several examples.

It is worth noting that there are several equivalent ways to define the ring of differential operators in characteristic zero. We discuss two such definitions in the case of the Weyl algebra over a field $K$ and show that they are equivalent when $\fchar(K) = 0$. However, when $\fchar(K) > 0$, these two definitions will no longer coincide. It therefore becomes necessary to fix either the field characteristic or a particular definition for the ring of differential operators, and in these notes, we will do the latter.

\subsection{The Ring of Differential Operators over an Arbitrary Ring}
Let $A\to B$ be a map of rings and let $M$ and $N$ be two $B$-modules. We may identify $B$ with a subring of $\End_B(M)$ via the map which sends an element $f \in B$ to the $B$-linear map $\hatf:m\mapsto f\cdot m$ on $M$. We denote the image of $f \in B$ in $\End_B(M)$ by $\hatf_M$ when there is risk of confusing the domain of $\hatf$ with some other module. Given a morphism $\alpha \in \Hom_B(M,N)$, we will often abuse notation and write $[\alpha, \hatf]$ to mean $\alpha \circ \hatf_M ~-~ \hatf_N\circ \alpha$. This is no longer an abuse of notation when $M = N$, in which case $[\alpha,\beta] = \alpha \circ \beta ~-~ \beta\circ\alpha$ is well-defined for any $\alpha, \beta \in \End_B(M)$.

\begin{defn}\label{defn:diff-ops}
	With $A,B,M$ and $N$ as above, we inductively define the collection of differential operators of order $k \in \bZ$, denoted $D^k_{B/A}(M,N)$, as follows:
	\begin{itemize}
		\item $D^k_{B/A}(M,N) = 0$ when $k < 0$
		\item $D^k_{B/A}(M,N) = \left\{\alpha \in \Hom_A(M,N) ~\middle|~ \left[\alpha,\hatf\right] \in D^{k-1}_{B/A}(M,N) ~ \text{ for all } f\in B\right\} $ when $k \geq 0$.
	\end{itemize}
	We set $D_{B/A}(M,N) = \bigcup_{k\in \bZ} D^k_{B/A}(M,N)$ and note that it is a left $B$-module under the action $fD = \hatf_N\circ D$ and a right $B$-module under the action $Df = D\circ \hatf_M$.
\end{defn}
\begin{rmk}\label{rmk:starting-index-of-diff-op-def}
	It is worth noting that $\alpha \in D_{B/A}(M,N)$ satisfies $[\alpha,\hatf] = 0 \in D^{-1}_{B/A}(M,N)$ exactly when $\alpha$ is $B$-linear, hence $D_{B/A}(M,N) = \Hom_B(M,N)$. Many sources, \cite{ginzburg_d-mod} and \cite{bernstein_d-mod} for instance, simply define $D^0_{B/A}(M,N) = \Hom_{B}(M,N)$ and proceed inductively from there.
\end{rmk}

\begin{notate}$ $
	\begin{itemize}
		\item We write $D_{B/A}(M)$ for $D_{B/A}(M,M)$ when $M = N$. In this case, $D_{B/A}(M)$ is a ring under pointwise-addition and composition, and is called the \emph{ring of differential operators over $M$}. Given two operators $\alpha,\beta \in D_{B/A}(M)$ we often drop the composition symbol and write $\alpha\beta$ to mean $\alpha\circ \beta$.
		\item When $B = M = N$, we simply write $D_{B/A}$.
		\item We write $D_B$ for the ring of differential operators over $B$ relative to the unique map $\bZ\to B$.
	\end{itemize}
\end{notate}
\noindent We will be primarily interested in $D_{R/K}$ for a $K$-algebra $R$.

It will be useful to establish some basic commutator relations. These have nothing to do with differential operators but will used extensively in later sections, often without comment.

\begin{prop}\label{prop:commutator-relations}
	Let $A$ be a (not necessarily commutative) ring, $M$ a left $A$-module and $\alpha,\beta,\gamma \in \End_A(M)$ $A$-linear maps on $M$. Then
	\begin{enumerate}[(a)]
		\item $[\alpha,\beta + \gamma] = [\alpha,\beta] + [\alpha, \gamma]$ and $[\alpha + \beta, \gamma] = [\alpha, \gamma] + [\beta,\gamma]$
		\item $[\hatf\alpha,\beta] = [\alpha,\hatf\beta] = \hatf[\alpha,\beta]$ for $f \in A$
		\item $[\alpha,\beta] = -[\beta,\alpha]$
		\item $[\alpha\beta,\gamma] = \alpha[\beta,\gamma] + [\alpha,\gamma]\beta$ and $[\alpha,\beta\gamma] = [\alpha,\beta]\gamma + \beta[\alpha,\gamma]$.
		\item $[\alpha,[[\beta,\gamma]] + [\beta,[\gamma,\alpha]] + [\gamma,[\alpha,\beta]] = 0$ (Jacobi identity).
	\end{enumerate}
\end{prop}
\begin{prf}
	These are all straightforward computations.
	\begin{enumerate}[(a)]
		\item We have that
			\begin{align*}
				[\alpha,\beta+\gamma] 
				  &~=~ \alpha(\beta+\gamma) - (\beta+\gamma)\alpha
				  ~=~ \alpha\beta - \beta\alpha + \alpha\gamma - \gamma\alpha
				  ~=~ [\alpha,\beta] + [\alpha,\gamma].
			\end{align*}
			A nearly identical computation gives us the other identity.
		\item Fix an element $f \in A$. Every operator $\lambda \in \End_A(M)$ is $A$-linear and hence $\hatf\circ\lambda = \lambda\circ \hatf$, i.e. $\hatf$ is in the center of $\End_A(M)$. The desired identity follows immediately from this fact.
		\item $[\alpha,\beta] = \alpha\beta - \beta\alpha = -(\beta\alpha - \alpha\beta) = -[\beta,\alpha]$. 
		\item This is more symbol pushing:
			\begin{align*}
				[\alpha\beta,\gamma] 
				  &= \alpha\beta\gamma - \gamma\alpha\beta \\
				  &= \alpha \beta\gamma - \alpha\gamma\beta + \alpha\gamma\beta - \gamma\alpha\beta \\
				  &= \alpha[\beta,\gamma] + [\alpha,\gamma]\beta.
			\end{align*}
			The other identity is proven nearly identically.
		\item The left hand side of this identity is
			\begin{align*}
				\alpha(\beta\gamma - \gamma\beta) - (\beta\gamma - \gamma\beta)\alpha + \beta(\gamma\alpha - \alpha\gamma) + (\gamma\alpha - \alpha\gamma)\beta + \gamma(\alpha\beta - \beta\alpha) - (\alpha\beta-\beta\alpha)\gamma.
			\end{align*}
			All terms cancel one this expression is fully expanded.
	\end{enumerate}
\end{prf}

\subsubsection{Order of Differential Operators}
Fix a commutative ring map $A\to B$. A differential operator $D \in \D_{B/A}$ is said to be of \emph{order $k$} if $D \in D^k_{B/A}$ but $D \not\in D^{k-1}_{B/A}$ and we say $\ord(D) = k$. In this section we aim to understand operators of order 1 and how order interacts with composition, addition, and the commutator. As the operator $0$ is contained in $D^k_{B/A}$ for every $k \in \bZ$, we say $\ord(0) = -\infty$.

\begin{lem}\label{lem:order-interactions}
	 Suppose $\alpha \in D^{m}_{B/A}$ and $\beta \in D^{n}_{B/A}$. The following hold:
	 \begin{enumerate}[(a)]
		 \item $\alpha+\beta \in D^d_{B/A}$ where $d = \max\{m,n\}$
		 \item $\alpha\beta \in D^{m+n}_{B/A}$
		 \item $[D,E] \in D^{m+n -1}_{B/A}$.
	 \end{enumerate}
\end{lem}
\begin{prf}
	\begin{enumerate}[(a)]
		\item This is clear from part (a) of \ref{prop:commutator-relations}; if $f \in B$ then

	\end{enumerate}
\end{prf}
\subsection{The Weyl Algebra}


\subsection{Examples of Differential Operators}
\section{D-Modules over a polynomial ring}

\subsection{Dimension of modules over the Weyl algebra}
The primary goal of this section is a proof of Bernstein's Inequality, a striking example of how the theory of $D$-modules can drastically differ from that of modules over commutative rings. To accomplish this, it is necessary to discuss several basic facts regarding the dimension of modules over the Weyl algebra, proofs of which we brazenly omit in eternal deference to Atiyah-Macdonald.
\subsubsection{Facts about Dimension}
\begin{thm}\label{thm:basic-dim-properties-A_n}
	Let $M$ be a finitely-generated left $A_n$-module and $N \subseteq M$ a submodule. Then
	\begin{enumerate}[(a)]
		\item $\dim(M) = \max\{d(N),d(M/N)\}$ 
		\item If $\dim(N) = \dim(M/N)$ then $m(M) = m(N) + m(M/N)$.
	\end{enumerate}
\end{thm}
\begin{prf}$ $
	\begin{enumerate}[(a)]
		\item Let us first see how the Hilbert polynomials of $M$, $N$ and $M/N$ related. Denote by $S_n$ the associated graded ring of $A_n$, and let $\Gamma$ be a good filtration of $M$ with respect to $\cB$. Let$\Gamma'$ and $\Gamma''$ be the induced filtrations for $N$ and $M/N$. We then obtain the following short exact sequence of associated graded $S_n$-modules:
		\begin{align*}
			0 \to \gr^{\Gamma'}N \to \gr^\Gamma M \to \gr^{\Gamma''}M/N \to 0.
		\end{align*}
		We know $\gr^\Gamma M$ is a finitely generated $S_n$-module since $\Gamma$ is good, hence $\gr^{\Gamma''}M/N$ is also finitely generated since it is isomorphic to a quotient of $\gr^\Gamma M$. Likewise, since $S_n$ is Noetherian and $\gr^{\Gamma'}N$ is isomorphic to a submodule of $\gr^\Gamma M$, $\gr^{\Gamma'}N$ is finitely generated. This tells us that $\Gamma'$ and $\Gamma''$ are both good filtrations.

		Now consider the short exact sequence of vector spaces
		\begin{align*}
			0 \to \Gamma'_k/\Gamma'_{k-1} \to \Gamma_k/\Gamma_{k-1} \to \Gamma''_{k}/\Gamma''_{k-1}\to 0
		\end{align*}
		for $0\leq k$. By the rank-nullity theorem, $\dim_K\Gamma_k/\Gamma_{k-1} = \dim_K\Gamma'_k/\Gamma'_{k-1} + \dim_K\Gamma''_{k}/\Gamma''_{k-1}$, so 
		\begin{align*}
			\sum_{k=0}^\infty\left(\dim_K\Gamma_k/\Gamma_{k-1}\right) = \sum_{k = 0}^\infty\left(\dim_K\Gamma'_k/\Gamma'_{k-1} + \dim_K\Gamma''_{k}/\Gamma''_{k-1}\right)
		\end{align*}
		and thus for $s >> 0$ we get
		\begin{align*}
			\chi(s,\Gamma,M) = \chi(s,\Gamma',M) + \chi(s,\Gamma'', N).
		\end{align*}

		As all of the above are polynomials with positive leading coefficients by \red{CITE THEOREM}, we get that $\deg\left(\chi(s,\Gamma',M) + \chi(s,\Gamma'', N)\right) = \deg\left(\chi(s,\Gamma',M)\right) + \left(\chi(s,\Gamma'', N)\right)$ and hence
		\begin{align*}
			\dim(M) = \max\left\{\dim(N), \dim(M)\right\}.
		\end{align*}
		\item If $\dim(M/N) = \dim(N)$ then the polynomials $\chi(s,\Gamma,M), \chi(s,\Gamma',M)$ and $\chi(s,\Gamma'', N)$ all have the same degree. This then implies that the leading term of $\chi(s,\Gamma, M)$ is equal to the sum of the leading terms of $\chi(s,\Gamma',N)$ and $\chi(s,\Gamma'',M/N)$.
	\end{enumerate}
\end{prf}

\subsubsection{Bernstein's Inequality}

\begin{thm}\label{thm:bern-inequality}
	If $M$ is a finitely-generated left $A_n(K)$-module, then either $n \leq \dim(M)\leq 2n$ or $M = 0$.
\end{thm}
\begin{prf}
	TO DO!!!!!!!!!
\end{prf}

\subsection{Holonomic Modules}

The Bernstein inequality tells us that a nonzero finitely-generated left $A_n(K)$-module $M$ must have dimension at least $n$ and at most $2n$. Those modules of minimal dimension are nice enough that we give them their very own name; we call them \emph{holonomic modules}.
\begin{defn}\label{defn:holonomic-modules}
	A finitely generated left $A_n(K)$-module $M$ is said to be \emph{holonomic} if either $M = 0$ or $\dim(M) = n$.
\end{defn}
Examples are easy to identify thanks to Bernstein. We know that $R = K[x_1,...,x_n]$ is holonomic since $\dim K[x_1,...,x_n] = n$, and furthermore, both $I$ and $R/I$ are holonomic when $I$ is any proper ideal of $R$. As another example, in the case that $n = 1$, for any nonzero ideal $I \subseteq A_1$ we have that $\dim(A_1/I) \leq 1$ by 
\subsubsection{Lemma on B-Functions}
Let $f$ be a polynomial in $K[x_1,...,x_n]$ and let $s$ be a new variable. We will consider the Weyl algebra $A_n(K(s))$ over the field of rational functions in $s$ and the $A_n(K(s))$-module generated by the formal symbol $f^s$, upon which a rational function $p \in K(s)$ acts in the obvious way and the operator $\partial_i$ acts by the formula
\begin{equation}\label{eqn:formula-preceeding-b-func}
	\partial_j\left(f^s\right) = \frac{s}{f}\cdot \frac{\partial f}{\partial x_i}.
\end{equation}
When $s$ is an integer and $f^s$ is treated not as a formal symbol but as a power, this action of course agrees with the existing action of $\partial_j$. The above formula means that $A_n(K(s))p^s$ is an $A_n(K(s))$-submodule of $K(s)[x_1,...,x_n,f^{-1}]$.

\begin{thm}\label{thm:b-functions-Weyl}
	Fix $f \in K[x_1,...,x_n]$. There exists a polynomial $B(s) \in K[s]$ and a differential operator $D(s)\in A_n(K)[s]$ such that
	\begin{align*}
		B(s)f^s = D(s) f^{s+1}.
	\end{align*}
	The set of all such $B(s)$ form an ideal in $K[s]$, the monic generator of which is called the \emph{Bernstein polynomial} of $f$ and is denoted by $b_f(s)$.
\end{thm}
\begin{example}\label{example:explicit-b-function1}
	Let $f = x_1^2+...+x_n^2$. Notice that
	\begin{align*}
		\partial_i^2 f^{s+1} = 4x_i^2(s+1)sf^{s-1} + 2(s+1)f^s.
	\end{align*}
	Letting $D = \partial_1^2 + ... + \partial_n^2$, we get that
	\begin{align*}
		D(f^{s+1})
		  &= \sum_{i=0}^n \left(4x_i^2(s+1)sf^{s-1} ~+~ 2(s+1)f^s\right) \\
		  &= 4(s+1)s(x_1^2+...+x_n^2)f^{s-1} + 2n(s+1)f^s \\
		  &= 2(s+1)(2s+ n)f^s,
	\end{align*}
	hence $b_f(s) = 2(s+1)(2s+n)f^s$.
\end{example}

\subsection{Inverse Image and Direct Image of Modules over the Weyl Algebra}
Here we introduce two operations on $D$-modules, inverse images and direct images. We discuss the former first. As should be expected by now, some algebraic constructions are brushed under the rug, the tensor product of bimodules perhaps chief among them. The reader may wish to visit \cite{d-mod-primer}, \cite{d-mod_ps_rt} or \cite{ginzburg_d-mod} if this is unfamiliar.

\subsubsection{Inverse Images}
Let $R = K[x_1,...,x_n]$, $S = K[y_1,...,y_m]$ and $M$ be a left $A_n$-module. We wish to build a left $A_m$-module from $M$ in a meaningful way. Suppose further that we are given a polynomial map $F:K^m\to K^n$ whose coordinate polynomials are $F_1,...,F_n\in K[y_1,...,y_m]$. Composition with $F$ gives a map of rings $\varphi:R\to S$ defined $f\mapsto f\circ F$, and in particular, we may view $S$ as an $R$-module via the $R$-action given by $\varphi$. The tensor product $S\otimes_R M$ is then an $S$-module denoted $F^*M$, and we want to turn it into an $A_m$-module. The action of polynomials on $F^*M$ is known, and we define the action of $\partial_{y_i}$ by
\begin{equation}\label{eqn:action-inv-img}\tag{$\ast$}
	\partial_{y_i}(q\otimes u) = \partial_{y_i}(q) \otimes u ~ + ~ \sum_{j=1}^n q\partial_{y_i}(F_j) \otimes \partial_{x_j} u.
\end{equation}
for $q\in S$ and $u\in M$ and extend by linearity. As the $y_i$'s and $\partial_{y_i}$'s generate $A_m$, to check that this does indeed give us a left $A_m$-action on $F^*M$ we need only check that (\ref{eqn:action-inv-img}) is compatible with the relations
\begin{align*}
	[\partial_{y_i}, y_j] &= \delta_{ij} \\
	[y_i,y_j] &= [\partial_{y_i},\partial_{y_j}] = 0
\end{align*}
where $\delta_{ij}$ is the Dirac delta function.

Let us check the first relation on an arbitrary generator $q\otimes u \in F^*M$, referring to the image of $y_j \in S$ in $A_m$ by $\hat{y}_j$ to avoid confusion:

% Possible confusion due to the fact that $[\partial_{y_i}, \hat{y}_j] = \delta_{ij}$ in $A_m$ whereas $\partial_{y_i}(y_j) = \delta_{ij}$ in $S$.
\begin{align*}
	\partial_{y_i}\hat{y}_j(q\otimes u)
	  &= \partial_{y_i}(y_j q \otimes u) ~+~ \sum_{k=1}^n y_jq\partial_{y_i}(F_k) \otimes \partial_{x_k}u \\
	  &= \big(\partial_{y_i}(y_j q)\big)\otimes u ~+~ y_j \sum_{k=1}^n q \partial_{y_i}(F_k) \otimes \partial_{x_k}u \\
	  &= q(\partial_{y_i}y_j)\otimes u ~+~ y_j(\partial_{y_i}(q))\otimes u ~+~ y_j \sum_{k=1}^n q \partial_{y_i}(F_k) \otimes \partial_{x_k}u \\
	  &= q\delta_{ij} \otimes u ~+~ y_j\left(\partial_{y_j}(q) \otimes u ~+~ \sum_{k=1}^n q\partial_{y_i}(F_k) \otimes \partial_{x_k}u\right) \\
	  &= \delta_{ij}(q\otimes u) ~+~ y_j\partial_{y_i}(q\otimes u) \\
	  &= \delta_{ij}(q\otimes u) ~+~ \hat{y}_j\big(\partial_{y_i}(q\otimes u)\big).
\end{align*}
Since the relation $[\partial_{y_i},\hat{y}_j]v = \delta_{ij}v$ holds when $v$ is of the form $q\otimes u \in F^*M$, it holds for arbitrary elements $v\in F^*M$ once we extend by linearity. The other two relations follow from an easy check and a few applications of Leibniz's rule, respectively. \red{In reality, I simply don't want to write out the relation $[\partial_{y_i},\partial_{y_j}]v = 0$, but perhaps it would be helpful to include in a future draft.} This means the following definition makes sense:

\begin{defn}\label{defn:inv-img}
	Let $F:K^m\to K^n$ be a polynomial map with components $F_1,...,F_n \in K[y_1,...,y_m]$ and let $M$ be a left $A_n$-module. Then $F^*M$ endowed with the $A_m$-action defined in (\ref{eqn:action-inv-img}) is a left $A_m$-module called the \emph{inverse image} of $M$ by the polynomial map $F$.
\end{defn}

\begin{rmk}\label{rmk:inv-img}
	The origin of the term ``inverse image'' here is clearer if we rephrase things in terms of geometry. If $X$ is a variety and $D_X$ is its sheaf of differential operators, then a sheaf $M$ over $X$ is said to be a left $D_X$-module if $M$ is a sheaf of left modules over $D_X$. Given a morphism $f:X\to Y$ of smooth algebraic varieties and a left $D_Y$-module $M$, then $f^*M$ is simply the sheaf-theoretic inverse image defined in \cite{hartshorne}.
\end{rmk}

\subsubsection{Direct Images}

\newpage
\printbibliography
\end{document}
